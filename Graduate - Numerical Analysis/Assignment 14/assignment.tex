%!TEX program = xelate
\input{structure.tex}
\usepackage{epstopdf}
\usepackage{graphics}
\usepackage{subfig}
\usepackage{listings}
\lstset{
  breaklines=true,
  xleftmargin=25pt,
  xrightmargin=25pt,
  aboveskip=0pt,
  belowskip=10pt,
  basicstyle=\ttfamily,
  showstringspaces=false,
  frame=ltrb,
  tabsize=4,
  numbers=left,
  numberstyle=\small,
  numbersep=8pt,
  morekeywords={*, factorial, sum, erlang},
  keywordstyle=\color{blue!70}, commentstyle=\color{red!50!green!50!blue!50},
}
\DeclareGraphicsExtensions{.eps,.ps,.jpg,.bmp}

\begin{document}

\title{Numerical Analysis \\ Assignment 13}
\date{\today}
\author{Chuan Lu}

\maketitle

\problem{1}{Problem 5.23}
\solution{(a)}{
Integrate (5.4.2) with respect to x on $[0, 1]$, we get from the convergence of the function series,
$$
\int_{0}^{1}(\frac{t}{e^t-1}e^{tx}-\frac{t}{e^t-1})dx = \sum_{j = 1}^{\infty}\frac{t^j}{j!}\int_{0}^{1}B_j(x)dx,
$$
thus
$$
1-\frac{t}{e^t-1} = \sum_{j=1}^{\infty}\frac{t^j}{j!}\int_{0}^{1}B_j(x)dx,
$$
with Taylor expansion of the left term of (5.4.5), we have $B_0 = 1$, thus
$$
\sum_{j=1}^{\infty}(B_j + \int_{0}^{1}B_j(x)dx)\frac{t^j}{j!} = 0.
$$
The left term can be regarded as a Taylor series of a function $f$ at $t = 0$ which satisfies $f(0) = 0$. By the uniqueness of Taylor expansion of a analytic function, we know $f\equiv 0$. Then for all $j > 0$,
$$
B_j + \int_{0}^{1}B_j(x)dx = 0.
$$
Now we know $B_0 = 1, ~B_1 = -\frac{1}{2}$, thus from definition (5.4.5),
$$
\frac{t}{e^t-1}+\frac{1}{2}t = 1+\sum_{j=2}^{\infty}B_j\frac{t^j}{j!} = \frac{t}{2}\frac{e^t+1}{e^t-1} \equiv g(t).
$$
We have
$$
g(-t) = -\frac{t}{2}\frac{e^{-t}+1}{e^{-t}-1} = -\frac{t}{2}\frac{1+e^t}{1-e^t} = g(t),
$$
hence $g(t)$ is an even function. Substitute $t = -t$ into last term,
$$
1+\sum_{j=2}^{\infty}(-1)^{j}B_j\frac{t^j}{j!} = g(-t) = g(t) = 1+\sum_{j=2}^{\infty}B_j\frac{t^j}{j!}.
$$
By simplification,
$$
\sum_{j = 1}^{\infty}B_{2j+1}\frac{t^{2j+1}}{(2j+1)!} = 0.
$$
With the same arguments and the uniqueness of Taylor expansion, we have
$$
B_{2j+1} = 0, ~\text{for all}~ j \ge 1.
$$
}
\solution{(b)}{
Take derivatives respective to $x$ on both sides of (5.4.2), 
$$
\frac{t^2}{e^t-1}e^{tx} = \sum_{j=1}^{\infty}B_j'(x)\frac{t^j}{j!}.
$$
Hence,
$$
\sum_{j=1}^{\infty}B_j'(x)\frac{t^j}{j!} = t\frac{t(e^{tx}-1)}{e^t-1} + \frac{t^2}{e^t-1} = \sum_{j=1}^{\infty}B_j(x)\frac{t^{j+1}}{j!} + \sum_{j=0}^{\infty}B_j\frac{t^{j+1}}{j!} = \sum_{j=2}^{\infty} jB_{j-1}(x)\frac{t^j}{j!} + \sum_{j=1}^{\infty}jB_{j-1}\frac{t^j}{j!}
$$
we have
$$
tB_1'(x) + \sum_{j=2}^{\infty}B_j'(x)\frac{t^j}{j!} = B_0t+\sum_{j=2}^{\infty}j(B_{j-1}(x)+B_{j-1})\frac{t^j}{j!}.
$$
Since $tB_1'(x) = B_0t$, with the uniqueness of Taylor expansion,
$$
B_j'(x) = j(B_{j-1}'(x)+B_{j-1}), ~\text{for all}~ j \ge 2.
$$
As proved in (a), $B_{2j+1} = 0 $ for all $j \ge 1$, the conclusion holds.
}

\problem{2}{Problem 5.31}
\lstinputlisting[language = MATLAB]{romberg.m}
\lstinputlisting[language = MATLAB]{prob2.m}
\lstinputlisting[language = MATLAB]{res2.m}
\solution{Cmp}{
When comparing with Simpson's rule and trapezoidal rule, we can find that romberg extrapolation converges quicker than the corresponding order of the two rules, but slower than the $2^N $ order of the two rules.
}

\problem{3}{Problem 5.37}
\lstinputlisting[language = MATLAB]{gauss_laguerre.m}
\solution{Sol}{
(a) By (5.6.11),
$$
\int_{0}^{\infty}e^{-x^2}dx = \int_{0}^{\infty}e^{-x}e^{x-x^2}dx.
$$

(b) By (5.6.11),
$$
\int_{0}^{\infty}\frac{x}{(1+x^2)^2}dx = \int_{0}^{\infty}e^{-x}\frac{xe^x}{(1+x^2)^2}dx.
$$

(c) By (5.6.11),
$$
\int_{0}^{\infty}\frac{\sin x}{x}dx = \int_{0}^{\infty}e^{-x}\frac{e^x\sin x}{x}dx.
$$

The result is as follows, from left to right are (a), (b), (c); the first part is the result, and the second part is the error.
}
\lstinputlisting[language = MATLAB]{res31.m}
\lstinputlisting[language = MATLAB]{res32.m}


\problem{4}{Problem 5.40}
\solution{(a)}{
Let $n \ge 1, ~h = b/n, ~x_j = jh $ for $j = 0, 1, \cdots , n$. For $x_{j-1}\le x\le x_j $, define
$$
f_n(x) = \frac{1}{h}((x_j-x)f(x_{j-1}) + (x-x_{j-1})f(x_j)),
$$
then
$$
\begin{aligned}
&I_n(f) = \sum_{j=1}^{n}\int_{x_{j-1}}^{x_j}\frac{1}{x^\alpha}\frac{1}{h}((x_j-x)f(x_{j-1})+(x-x_{j-1})f(x_j))dx = \sum_{k=0}^{n}w_kf(x_k), \\
\text{with} \\
&w_0 = \frac{1}{h}\int_{x_0}^{x_1}\frac{1}{x^\alpha}(x_1-x)dx, ~w_n = \frac{1}{h}\int_{x_{n-1}}^{x_n}\frac{1}{x^\alpha}(x-x_{n-1})dx, \\
&w_j = \frac{1}{h}\int_{x_{j-1}}^{x_j}(x-x_{j-1})\frac{1}{x^\alpha}dx+\frac{1}{h}\int_{x_j}^{x_{j+1}}(x_{j+1}-x)\frac{1}{x^\alpha}dx.
\end{aligned}
$$
To simplify, let $x-x_{j-1} = uh $,
$$
\frac{1}{h}\int_{x_{j-1}}^{x_j}(x-x_{j-1})\frac{1}{x^\alpha}dx = \frac{1}{h^{\alpha-1}}\int_{0}^{1}\frac{u}{(j-1+u)^\alpha}du,
$$
$$
\frac{1}{h}\int_{x_{j-1}}^{x_j}(x_j-x)\frac{1}{x^\alpha}dx = \frac{1}{h^{\alpha-1}}\int_{0}^{1}\frac{1-u}{(j-1+u)^\alpha}du.
$$
Define
$$
\phi_1(k) = \int_{0}^{1}\frac{u}{(k-1+u)^\alpha}dx, ~\phi_2(k) = \int_{0}^{1}\frac{1-u}{(k-1+u)^\alpha}dx,
$$
then
$$
w_0 = \frac{1}{h^{\alpha-1}}\phi_2(1), ~w_n = \frac{1}{h^{\alpha-1}}\phi_1(n), ~w_j = \frac{1}{h^{\alpha-1}}(\phi_1(j)+\phi_2(j+1)).
$$
From (5.6.22) we know,
$$
|I(f)-I_n(f)| \le \frac{h^2}{8}\lVert f''\rVert_{\infty}\int_{0}^{b}\frac{1}{x^\alpha}dx.
$$
}
\solution{(b)}{
The code and result are as follows. For (ii), after a change of variable, we get
$$
\int_{0}^{1}\frac{\pi/(2\sin u)}{u^{1-\pi/2}}du,
$$
and $f = \frac{1}{\sin u}$ still has a singularity on $u = 0$.
}
\lstinputlisting[language = MATLAB]{product_trapezoidal.m}
\lstinputlisting[language = MATLAB]{prob4.m}
\lstinputlisting[language = MATLAB]{res4.m}

\end{document}